{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up minikube and usage of docker image for torch processes + kale in AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will follow: \n",
    "\n",
    "* For minikube: [minikube_sipecam/setup](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/setup#aws)\n",
    "\n",
    "* docker image for torch: [torch/1.4.0_0.5.0/Dockerfile](https://github.com/CONABIO/kube_sipecam/blob/master/dockerfiles/torch/1.4.0_0.5.0/Dockerfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use [minikube_sipecam/deployments/torch/hostpath_pv](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/deployments/torch/hostpath_pv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In AWS account we can select ami: `minikube-sipecam-gpu` which has next description:\n",
    "\n",
    "Based in k8s-1.16-debian-buster-amd64-hvm-ebs-2020-04-27 - ami-0ab39819e336a3f3f Contains kubectl 1.19.1 minikube 1.13.0 kubeflow 1.0.2  nvidia-docker Docker version 19.03.4, build 9013bf583a nvidia-container-runtime runc version 1.0.0-rc8+dev commit: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 spec: 1.0.1-dev\n",
    "\n",
    "\n",
    "and instance `p2.xlarge` with `100` gb of disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use next bash script for user data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "##variables:\n",
    "region=us-west-2\n",
    "name_instance=minikube-gpu-18-09-2020\n",
    "##System update\n",
    "apt-get update -yq\n",
    "##Tag instance\n",
    "INSTANCE_ID=$(curl -s http://instance-data/latest/meta-data/instance-id)\n",
    "PUBLIC_IP=$(curl -s http://instance-data/latest/meta-data/public-ipv4)\n",
    "aws ec2 create-tags --resources $INSTANCE_ID --tag Key=Name,Value=$name_instance-$PUBLIC_IP --region=$region\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ssh to instance, all commands will be executed as root**\n",
    "\n",
    "`sudo su`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next will start minikube create device plugin for nvidia and kubeflow pods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd /root && minikube start --driver=none\n",
    "\n",
    "\n",
    "kubectl create -f /root/nvidia-device-plugin.yml\n",
    "\n",
    "\n",
    "cd /opt/kf-test && /root/kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pods and status with:\n",
    "\n",
    "```\n",
    "minikube status\n",
    "\n",
    "minikube\n",
    "type: Control Plane\n",
    "host: Running\n",
    "kubelet: Running\n",
    "apiserver: Running\n",
    "kubeconfig: Configured\n",
    "```\n",
    "\n",
    "```\n",
    "kubectl get pods -n kubeflow\n",
    "\n",
    "#all running except:\n",
    "spark-operatorcrd-cleanup-2p7x2                                0/2     Completed   0          7m6s\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To access kubeflow UI set:**\n",
    "\n",
    "```\n",
    "export INGRESS_HOST=$(minikube ip)\n",
    "export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==\"http2\")].nodePort}')\n",
    "echo $INGRESS_PORT\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:$INGRESS_PORT\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments and services \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_PV=hostpath-pv\n",
    "TORCH_PVC=hostpath-pvc\n",
    "TORCH_URL=https://raw.githubusercontent.com/CONABIO/kube_sipecam/master/minikube_sipecam/deployments/torch/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create storage:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_PV.yaml\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_PVC.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next for GPU deployment (for testing notebooks):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create service:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_LOAD_BALANCER_SERVICE_GPU=loadbalancer-torch-1.4.0_0.5.0-hostpath-pv-gpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_LOAD_BALANCER_SERVICE_GPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create deployment:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_JUPYTERLAB_SERVICE_GPU=jupyterlab-torch-1.4.0_0.5.0-hostpath-pv-gpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_JUPYTERLAB_SERVICE_GPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:30001/torchurl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next for CPU deployment and launch via kale:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create service:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_LOAD_BALANCER_SERVICE_CPU=loadbalancer-torch-1.4.0_0.5.0-hostpath-pv-cpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_LOAD_BALANCER_SERVICE_CPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create deployment:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_JUPYTERLAB_SERVICE_CPU=jupyterlab-torch-1.4.0_0.5.0-hostpath-pv-cpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_JUPYTERLAB_SERVICE_CPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:30002/torchurl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "If disk is full which could happen if a kubeflow pipeline will be uploaded from kale:\n",
    "\n",
    "```\n",
    "HTTP response headers: HTTPHeaderDict({'Date': 'Tue, 01 Sep 2020 18:12:22 GMT', 'Content-Length': '487', 'Content-Type': 'text/plain; charset=utf-8'})\n",
    "HTTP response body: {\"error_message\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\",\"error_details\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\"}\n",
    "```\n",
    "\n",
    "Delete kubeflow (MAD-Mex and geonode deployments)\n",
    "\n",
    "To free space:\n",
    "\n",
    "```\n",
    "minikube stop\n",
    "minikube delete\n",
    "```\n",
    "\n",
    "Check:\n",
    "\n",
    "```\n",
    "docker system df\n",
    "docker system prune --all --volumes\n",
    "rm -r /root/.minikube/*\n",
    "rm -r /root/.kube/*\n",
    "rm -r /opt/kf-test\n",
    "```\n",
    "\n",
    "Start again (being in root dir):\n",
    "\n",
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "ref: https://github.com/aws-samples/eks-workshop/issues/639\n",
    "\n",
    "If there's problems with geonode (because stack of docker-compose was deleted, clone again repo and deploy geonode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up minikube and usage of docker image for torch processes + kale in AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will follow: \n",
    "\n",
    "* For minikube: [minikube_sipecam/setup](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/setup#aws)\n",
    "\n",
    "* docker image for torch: [torch/1.4.0_0.5.0/Dockerfile](https://github.com/CONABIO/kube_sipecam/blob/master/dockerfiles/torch/1.4.0_0.5.0/Dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use [minikube_sipecam/deployments/torch/hostpath_pv](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/deployments/torch/hostpath_pv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance\n",
    "\n",
    "In AWS we can select ami: `k8s-1.16-debian-buster-amd64-hvm-ebs-2020-04-27 - ami-0ab39819e336a3f3f` and instance `p2.xlarge` with `100` gb of disk.\n",
    "\n",
    "Use next bash script for user data to install `kubectl`, download `minikube` and `kfctl`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "##variables:\n",
    "region=us-west-2\n",
    "user=admin\n",
    "name_instance=minikube-gpu\n",
    "shared_volume=/shared_volume\n",
    "##System update\n",
    "export DEBIAN_FRONTEND=noninteractive\n",
    "apt-get update -yq\n",
    "##Install awscli\n",
    "apt-get install -y python3-pip build-essential && pip3 install --upgrade pip\n",
    "pip3 install awscli --upgrade\n",
    "##Tag instance\n",
    "INSTANCE_ID=$(curl -s http://instance-data/latest/meta-data/instance-id)\n",
    "PUBLIC_IP=$(curl -s http://instance-data/latest/meta-data/public-ipv4)\n",
    "aws ec2 create-tags --resources $INSTANCE_ID --tag Key=Name,Value=$name_instance-$PUBLIC_IP --region=$region\n",
    "#check if locales are ok with next lines:\n",
    "echo \"export LC_ALL=C.UTF-8\" >> /root/.profile\n",
    "echo \"export LANG=C.UTF-8\" >> /root/.profile\n",
    "echo \"export mount_point=$shared_volume\" >> /root/.profile\n",
    "wget http://us.download.nvidia.com/tesla/418.116.00/NVIDIA-Linux-x86_64-418.116.00.run -O /root/NVIDIA-Linux-x86_64-418.116.00.run\n",
    "cd /root/ && chmod a+x NVIDIA-Linux-x86_64-418.116.00.run && ./NVIDIA-Linux-x86_64-418.116.00.run --accept-license --silent\n",
    "curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey |   sudo apt-key add -\n",
    "distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n",
    "curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list |   sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n",
    "apt-get update\n",
    "apt-get install -y nvidia-docker2 nvidia-container-runtime\n",
    "echo '{\n",
    "    \"default-runtime\": \"nvidia\",\n",
    "    \"runtimes\": {\n",
    "        \"nvidia\": {\n",
    "            \"path\": \"/usr/bin/nvidia-container-runtime\",\n",
    "            \"runtimeArgs\": []\n",
    "        }\n",
    "    }\n",
    "}' > /etc/docker/daemon.json\n",
    "systemctl start docker\n",
    "usermod -aG docker $user\n",
    "newgrp docker\n",
    "#Create shared volume\n",
    "mkdir $shared_volume\n",
    "#kubectl installation\n",
    "curl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\n",
    "chmod +x ./kubectl\n",
    "mv ./kubectl /usr/local/bin/kubectl\n",
    "kubectl version --client\n",
    "#bash completion, needs to exit and enter again to take effect\n",
    "#echo \"source <(kubectl completion bash)\" >> /root/.bashrc\n",
    "#apt-get install -y bash-completion\n",
    "#minikube download\n",
    "curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n",
    "  && chmod +x minikube\n",
    "cp minikube /usr/local/bin/\n",
    "install minikube /usr/local/bin/\n",
    "apt-get install conntrack -y\n",
    "#kfctl download\n",
    "cd /root && wget https://github.com/kubeflow/kfctl/releases/download/v1.0.2/kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "tar -xvf kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "echo \"export PATH=$PATH:$(pwd)\" >> /root/.profile\n",
    "# Set KF_NAME to the name of your Kubeflow deployment. This also becomes the\n",
    "# name of the directory containing your configuration.\n",
    "# For example, your deployment name can be 'my-kubeflow' or 'kf-test'.\n",
    "echo \"export KF_NAME=kf-test\" >> ~/.profile\n",
    "echo \"export BASE_DIR=/opt\" >> ~/.profile\n",
    "source ~/.profile\n",
    "echo \"export KF_DIR=${BASE_DIR}/${KF_NAME}\" >> ~/.profile\n",
    "wget https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.6.0/nvidia-device-plugin.yml -O /root/nvidia-device-plugin.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check installation in AWS instance with: `tail -n 15  /var/log/cloud-init-output.log`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check installation of NVIDIA toolkit: `nvidia-smi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ssh to instance, all commands will be executed as `root`**\n",
    "\n",
    "```\n",
    "sudo su\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next will install, start `minikube` using `none` driver and install `kfctl`:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "\n",
    "kubectl create -f /root/nvidia-device-plugin.yml\n",
    "\n",
    "#check: kubectl describe daemonsets -n kube-system\n",
    "\n",
    "#check: kubectl describe daemonsets.app -n kube-system\n",
    "\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check pods and status with:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`minikube status`\n",
    "\n",
    "```\n",
    "minikube\n",
    "type: Control Plane\n",
    "host: Running\n",
    "kubelet: Running\n",
    "apiserver: Running\n",
    "kubeconfig: Configured\n",
    "```\n",
    "\n",
    "`kubectl get pods -n kubeflow`\n",
    "\n",
    "```\n",
    "#all running except:\n",
    "spark-operatorcrd-cleanup-2p7x2                                0/2     Completed   0          7m6s\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To access kubeflow UI set:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "export INGRESS_HOST=$(minikube ip)\n",
    "export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==\"http2\")].nodePort}')\n",
    "echo $INGRESS_PORT\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:$INGRESS_PORT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments and services \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_PV=hostpath-pv\n",
    "TORCH_PVC=hostpath-pvc\n",
    "TORCH_URL=https://raw.githubusercontent.com/CONABIO/kube_sipecam/master/minikube_sipecam/deployments/torch/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create storage:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_PV.yaml\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_PVC.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next for GPU deployment (for testing notebooks):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create service:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_LOAD_BALANCER_SERVICE_GPU=loadbalancer-torch-1.4.0_0.5.0-hostpath-pv-gpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_LOAD_BALANCER_SERVICE_GPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create deployment:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_JUPYTERLAB_SERVICE_GPU=jupyterlab-torch-1.4.0_0.5.0-hostpath-pv-gpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_JUPYTERLAB_SERVICE_GPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:30001/torchurl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next for CPU deployment and launch via kale:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create service:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_LOAD_BALANCER_SERVICE_CPU=loadbalancer-torch-1.4.0_0.5.0-hostpath-pv-cpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_LOAD_BALANCER_SERVICE_CPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create deployment:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TORCH_JUPYTERLAB_SERVICE_CPU=jupyterlab-torch-1.4.0_0.5.0-hostpath-pv-cpu\n",
    "kubectl create -f $TORCH_URL/hostpath_pv/$TORCH_JUPYTERLAB_SERVICE_CPU.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:30002/torchurl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "If disk is full which could happen if a kubeflow pipeline will be uploaded from kale:\n",
    "\n",
    "```\n",
    "HTTP response headers: HTTPHeaderDict({'Date': 'Tue, 01 Sep 2020 18:12:22 GMT', 'Content-Length': '487', 'Content-Type': 'text/plain; charset=utf-8'})\n",
    "HTTP response body: {\"error_message\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\",\"error_details\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\"}\n",
    "```\n",
    "\n",
    "Delete kubeflow (MAD-Mex and geonode deployments)\n",
    "\n",
    "To free space:\n",
    "\n",
    "```\n",
    "minikube stop\n",
    "minikube delete\n",
    "```\n",
    "\n",
    "Check:\n",
    "\n",
    "```\n",
    "docker system df\n",
    "docker system prune --all --volumes\n",
    "rm -r /root/.minikube/*\n",
    "rm -r /root/.kube/*\n",
    "rm -r /opt/kf-test\n",
    "```\n",
    "\n",
    "Start again (being in root dir):\n",
    "\n",
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "ref: https://github.com/aws-samples/eks-workshop/issues/639\n",
    "\n",
    "If there's problems with geonode (because stack of docker-compose was deleted, clone again repo and deploy geonode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

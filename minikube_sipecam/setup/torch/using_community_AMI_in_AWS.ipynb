{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up minikube and usage of docker image for torch processes + kale in AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will follow: \n",
    "\n",
    "* For minikube: [minikube_sipecam/setup](https://github.com/CONABIO/kube_sipecam/tree/master/minikube_sipecam/setup#aws)\n",
    "\n",
    "* docker image for torch: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use [minikube_sipecam/deployments/torch/hostpath_pv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance\n",
    "\n",
    "In AWS we can select ami: `k8s-1.16-debian-buster-amd64-hvm-ebs-2020-04-27 - ami-0ab39819e336a3f3f` and instance `p2.xlarge` with `100` gb of disk.\n",
    "\n",
    "Use next bash script for user data to install `kubectl`, download `minikube` and `kfctl`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "##variables:\n",
    "region=us-west-2\n",
    "user=admin\n",
    "name_instance=minikube-gpu\n",
    "shared_volume=/shared_volume\n",
    "##System update\n",
    "export DEBIAN_FRONTEND=noninteractive\n",
    "apt-get update -yq\n",
    "##Install awscli\n",
    "apt-get install -y python3-pip build-essential && pip3 install --upgrade pip\n",
    "pip3 install awscli --upgrade\n",
    "##Tag instance\n",
    "INSTANCE_ID=$(curl -s http://instance-data/latest/meta-data/instance-id)\n",
    "PUBLIC_IP=$(curl -s http://instance-data/latest/meta-data/public-ipv4)\n",
    "aws ec2 create-tags --resources $INSTANCE_ID --tag Key=Name,Value=$name_instance-$PUBLIC_IP --region=$region\n",
    "#check if locales are ok with next lines:\n",
    "echo \"export LC_ALL=C.UTF-8\" >> /root/.profile\n",
    "echo \"export LANG=C.UTF-8\" >> /root/.profile\n",
    "echo \"export mount_point=$shared_volume\" >> /root/.profile\n",
    "wget http://us.download.nvidia.com/tesla/418.116.00/NVIDIA-Linux-x86_64-418.116.00.run -O /root/NVIDIA-Linux-x86_64-418.116.00.run\n",
    "cd /root/ && chmod a+x NVIDIA-Linux-x86_64-418.116.00.run && ./NVIDIA-Linux-x86_64-418.116.00.run --accept-license --silent\n",
    "curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey |   sudo apt-key add -\n",
    "distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n",
    "curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list |   sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n",
    "apt-get update\n",
    "apt-get install -y nvidia-docker2 nvidia-container-runtime\n",
    "echo '{\n",
    "    \"default-runtime\": \"nvidia\",\n",
    "    \"runtimes\": {\n",
    "        \"nvidia\": {\n",
    "            \"path\": \"/usr/bin/nvidia-container-runtime\",\n",
    "            \"runtimeArgs\": []\n",
    "        }\n",
    "    }\n",
    "}' > /etc/docker/daemon.json\n",
    "systemctl start docker\n",
    "usermod -aG docker $user\n",
    "newgrp docker\n",
    "#Create shared volume\n",
    "mkdir $shared_volume\n",
    "#kubectl installation\n",
    "curl -LO \"https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl\"\n",
    "chmod +x ./kubectl\n",
    "mv ./kubectl /usr/local/bin/kubectl\n",
    "kubectl version --client\n",
    "#bash completion, needs to exit and enter again to take effect\n",
    "#echo \"source <(kubectl completion bash)\" >> /root/.bashrc\n",
    "#apt-get install -y bash-completion\n",
    "#minikube download\n",
    "curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \\\n",
    "  && chmod +x minikube\n",
    "cp minikube /usr/local/bin/\n",
    "install minikube /usr/local/bin/\n",
    "apt-get install conntrack -y\n",
    "#kfctl download\n",
    "cd /root && wget https://github.com/kubeflow/kfctl/releases/download/v1.0.2/kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "tar -xvf kfctl_v1.0.2-0-ga476281_linux.tar.gz\n",
    "echo \"export PATH=$PATH:$(pwd)\" >> /root/.profile\n",
    "# Set KF_NAME to the name of your Kubeflow deployment. This also becomes the\n",
    "# name of the directory containing your configuration.\n",
    "# For example, your deployment name can be 'my-kubeflow' or 'kf-test'.\n",
    "echo \"export KF_NAME=kf-test\" >> ~/.profile\n",
    "echo \"export BASE_DIR=/opt\" >> ~/.profile\n",
    "source ~/.profile\n",
    "echo \"export KF_DIR=${BASE_DIR}/${KF_NAME}\" >> ~/.profile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check installation in AWS instance with: `tail -n 15  /var/log/cloud-init-output.log`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ssh to instance, all commands will be executed as `root`**\n",
    "\n",
    "```\n",
    "sudo su\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next will install, start `minikube` using `none` driver and install `kfctl`:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "\n",
    "kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.6.0/nvidia-device-plugin.yml\n",
    "\n",
    "#check: kubectl describe daemonsets -n kube-system\n",
    "\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check pods and status with:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`minikube status`\n",
    "\n",
    "```\n",
    "minikube\n",
    "type: Control Plane\n",
    "host: Running\n",
    "kubelet: Running\n",
    "apiserver: Running\n",
    "kubeconfig: Configured\n",
    "```\n",
    "\n",
    "`kubectl get pods -n kubeflow`\n",
    "\n",
    "```\n",
    "#all running except:\n",
    "spark-operatorcrd-cleanup-2p7x2                                0/2     Completed   0          7m6s\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To access kubeflow UI set:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "export INGRESS_HOST=$(minikube ip)\n",
    "export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==\"http2\")].nodePort}')\n",
    "echo $INGRESS_PORT\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:$INGRESS_PORT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployments and services \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "MAD_MEX_PV=hostpath-pv\n",
    "MAD_MEX_PVC=hostpath-pvc\n",
    "MAD_MEX_URL=https://raw.githubusercontent.com/CONABIO/kube_sipecam/master/minikube_sipecam/deployments/MAD_Mex/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create storage:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kubectl create -f $MAD_MEX_URL/hostpath_pv/$MAD_MEX_PV.yaml\n",
    "kubectl create -f $MAD_MEX_URL/hostpath_pv/$MAD_MEX_PVC.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create service:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loadbalancer-torch-1-4-0-0-5-0-hostpath-pv.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "kind: Service\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "        name: loadbalancer-torch-1-4-0-0-5-0-hostpath-pv\n",
    "        namespace: kubeflow\n",
    "spec:\n",
    "        type: LoadBalancer\n",
    "        ports:\n",
    "                - port: 8888\n",
    "                  targetPort: 8888\n",
    "                  protocol: TCP\n",
    "                  nodePort: 30001 #select port of your preference\n",
    "        selector:\n",
    "                app: jupyterlab-torch-1-4-0-0-5-0-app\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kubectl create -f loadbalancer-torch-1-4-0-0-5-0-hostpath-pv.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create deployment:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile\n",
    "\n",
    "```\n",
    "#nbclient 0.5.0 requires nbformat>=5.0, but you'll have nbformat 4.4.0 which is incompatible.\n",
    "#kfp 0.3.0 requires kfp-server-api<0.4.0,>=0.2.5, but you'll have kfp-server-api 0.1.18.3 which is incompatible.\n",
    "FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04\n",
    "\n",
    "ENV TIMEZONE America/Mexico_City\n",
    "ENV LANG C.UTF-8\n",
    "ENV LC_ALL C.UTF-8\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "ENV DEB_BUILD_DEPS=\"sudo nano less git wget curl python3-dev python3-pip python3-setuptools software-properties-common\"\n",
    "ENV DEB_PACKAGES=\"\"\n",
    "ENV PIP_PACKAGES_COMMON=\"numpy==1.18.0 scipy==1.4.1 pandas matplotlib seaborn\"\n",
    "ENV PIP_PACKAGES_TORCH=\"torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html\"\n",
    "ENV PIP_PACKAGES_KALE=\"setuptools==41.2 click==7.0 six==1.12.0 urllib3==1.24.2 kubeflow-kale==0.5.0\"\n",
    "\n",
    "RUN apt-get update && export $DEBIAN_FRONTEND && \\\n",
    "    echo $TIMEZONE > /etc/timezone && apt-get install -y tzdata\n",
    "\n",
    "RUN apt-get update && apt-get install -y $DEB_BUILD_DEPS $DEB_PACKAGES && pip3 install --upgrade pip\n",
    "\n",
    "RUN curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - && apt-get install -y nodejs\n",
    "\n",
    "RUN pip3 install jupyter \"jupyterlab<2.0.0\" --upgrade\n",
    "\n",
    "RUN jupyter notebook --generate-config && sed -i \"s/#c.NotebookApp.password = .*/c.NotebookApp.password = u'sha1:115e429a919f:21911277af52f3e7a8b59380804140d9ef3e2380'/\" /root/.jupyter/jupyter_notebook_config.py\n",
    "\n",
    "RUN pip3 install $PIP_PACKAGES_COMMON --upgrade\n",
    "RUN pip3 install $PIP_PACKAGES_TORCH --upgrade\n",
    "RUN pip3 install $PIP_PACKAGES_KALE --upgrade\n",
    "\n",
    "RUN jupyter labextension install kubeflow-kale-launcher\n",
    "\n",
    "VOLUME [\"/shared_volume\"]\n",
    "\n",
    "ENV NB_PREFIX torchurl\n",
    "\n",
    "ENTRYPOINT [\"/usr/local/bin/jupyter\", \"lab\", \"--ip=0.0.0.0\", \"--no-browser\", \"--allow-root\", \"--LabApp.allow_origin='*'\", \"--LabApp.base_url=torchurl\"]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "REPO_URL=sipecam/torch-kale\n",
    "BUILD_DIR=$(pwd)\n",
    "TORCH_AND_KALE_VERSION=1.4.0_0.5.0\n",
    "docker build $BUILD_DIR --force-rm -t $REPO_URL:$TORCH_AND_KALE_VERSION\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is not needed entry nvidia.com/gpu when using kale to launch to kubeflow pipelines. Although it's needed when testing the notebook:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`jupyterlab-torch-1-4-0-0-5-0-hostpath-pv.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kind: Deployment\n",
    "apiVersion: apps/v1\n",
    "metadata:\n",
    "        name: jupyterlab-torch-1-4-0-0-5-0\n",
    "        namespace: kubeflow\n",
    "spec:\n",
    "        replicas: 1 # This is the number of containers that are going to be deployed.\n",
    "        selector:\n",
    "                matchLabels:\n",
    "                        app: jupyterlab-torch-1-4-0-0-5-0-app\n",
    "        template:\n",
    "                metadata:\n",
    "                        labels:\n",
    "                                app: jupyterlab-torch-1-4-0-0-5-0-app\n",
    "                spec:\n",
    "                        containers: \n",
    "                        - name: jupyterlab-torch-1-4-0-0-5-0\n",
    "                          imagePullPolicy: Always\n",
    "                          image: sipecam/torch-kale:1.4.0_0.5.0\n",
    "                          ports:\n",
    "                                  - containerPort: 9999\n",
    "                          env:\n",
    "                                  - name: mount_point\n",
    "                                    value: /shared_volume\n",
    "                                  - name: LC_ALL\n",
    "                                    value: C.UTF-8\n",
    "                                  - name: LANG\n",
    "                                    value: C.UTF-8\n",
    "                          resources:\n",
    "                                  requests:\n",
    "                                          cpu: \".5\" # This value depends of type of AWS instance chosen\n",
    "                                          memory: 15Gi # This value depends of type of AWS instance chosen\n",
    "                                  limits:\n",
    "                                          cpu: \".5\" # This value depends of type of AWS instance chosen\n",
    "                                          memory: 15Gi # This value depends of type of AWS instance chosen\n",
    "                                          nvidia.com/gpu: 1\n",
    "                          volumeMounts:\n",
    "                                  - name: hostpath-pv\n",
    "                                    mountPath: \"/shared_volume\"\n",
    "                        volumes:\n",
    "                        - name: hostpath-pv\n",
    "                          persistentVolumeClaim:\n",
    "                                  claimName: hostpath-pvc \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kubectl create -f jupyterlab-torch-1-4-0-0-5-0-hostpath-pv.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And go to:**\n",
    "\n",
    "```\n",
    "http://<ipv4 of ec2 instance>:30001/torchurl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "If disk is full which could happen if a kubeflow pipeline will be uploaded from kale:\n",
    "\n",
    "```\n",
    "HTTP response headers: HTTPHeaderDict({'Date': 'Tue, 01 Sep 2020 18:12:22 GMT', 'Content-Length': '487', 'Content-Type': 'text/plain; charset=utf-8'})\n",
    "HTTP response body: {\"error_message\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\",\"error_details\":\"Error creating pipeline: Create pipeline failed: InternalServerError: Failed to store b2fa5a70-cab4-4c89-8784-9c0cb118d1b4: Storage backend has reached its minimum free disk threshold. Please delete a few objects to proceed.\"}\n",
    "```\n",
    "\n",
    "Delete kubeflow (MAD-Mex and geonode deployments)\n",
    "\n",
    "To free space:\n",
    "\n",
    "```\n",
    "minikube stop\n",
    "minikube delete\n",
    "```\n",
    "\n",
    "Check:\n",
    "\n",
    "```\n",
    "docker system df\n",
    "docker system prune --all --volumes\n",
    "rm -r /root/.minikube/*\n",
    "rm -r /root/.kube/*\n",
    "rm -r /opt/kf-test\n",
    "```\n",
    "\n",
    "Start again (being in root dir):\n",
    "\n",
    "```\n",
    "CONFIG_URI=\"https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.2.yaml\"\n",
    "source ~/.profile\n",
    "chmod gou+wrx -R /opt/\n",
    "mkdir -p ${KF_DIR}\n",
    "#minikube start\n",
    "cd /root && minikube start --driver=none\n",
    "#kubeflow start\n",
    "cd ${KF_DIR}\n",
    "\n",
    "wget $CONFIG_URI\n",
    "wget https://codeload.github.com/kubeflow/manifests/tar.gz/v1.0.2 -O v1.0.2.tar.gz\n",
    "\n",
    "```\n",
    "\n",
    "change kfctl_k8s_istio.v1.0.2.yaml at the end uri:\n",
    "\n",
    "```\n",
    "#this section:\n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz\n",
    "#for: \n",
    "  repos:\n",
    "  - name: manifests\n",
    "    uri: file:///opt/kf-test/v1.0.2.tar.gz\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```\n",
    "kfctl apply -V -f kfctl_k8s_istio.v1.0.2.yaml\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "ref: https://github.com/aws-samples/eks-workshop/issues/639\n",
    "\n",
    "If there's problems with geonode (because stack of docker-compose was deleted, clone again repo and deploy geonode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
